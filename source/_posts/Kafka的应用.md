---
title: Kafka的应用
date: 2019-11-20 10:44:34
tags:
- 大数据
toc: true
copyright: true
---

# 一、Kafka的应用

### 1、Spark/Spark Streaming 实时计算

充当消费者，消费Kafka的消息。也就是说Spark大约有90%的数据会来自kafka。
### 2、kafka有两种消息发送模式
####  2.1、点对点（一对一）模式。

只能一个生产者，一个消费者这样，消费者消费一条数据，然后表示接收到了，然后再回复一个确认收到，则消费一条数据，消息队列就删掉一条数据。如果想要多个消费者消费消息，就不行了。

 #### 2.2、发布订阅（publish/subscribe ）

​		发布订阅有两种，一种是生产者把消息发送到队列里，然后主动推送消息给消费者，有点类似你订阅的微信公众号，只要有新的消息就会推送给消费者。但是这种机制有一个缺点就是，比如你生产者生产消息的速度是100M/s，但是，你多个消费者可能处理消息的速度都不一样，有的50M/s，有的200M/s，而直接推送消息这种方式，处理速度慢的消费者就会直接崩掉。而处理速度快的又会造成很大的资源浪费。第二种是消费者主动拉取数据，会根据自身数据处理速度拉取。但是有问题，消费者要隔一段时间的轮询消息队列，看有没有新的消息产生。假如某种情况下，这样也容易造成一些资源浪费。kafka的发布订阅方式是消费者主动拉取数据。

### 3、Kafka中的相关定义

 #### 3.1、Offset

​		作用就是记录消费位，比如你消费到第6条，broker挂了，它会保存记录到zookeeper 里，kafka的0.9版本之前都是保存在zk中，之后就直接保存在kafka里也就是本地存储。不管你保存在zk也好，也是本地kafka集群也好，offset都是用来管理消息消费偏移量的
为什么要改保存到kafka集群本地呢？你zk存的好好的，首先消费者本身跟kafka直接连接的，我在kafka里面获取数据的同时，还要维护跟zk的连接，首先消费者是以拉取的方式获取消息的，本身拉取速度是非常快的，可能你消费者一秒要拉取消息好几次，还要跟zk这边打交道好几次，这样太频繁了，就会影响效率，而zk本身是来提供各大框架之间润滑技的作用，那你此时这么高并发的请求，存到zk里面也不好，后来把offset存到本地，这个本地不是本地磁盘，而是存到kafka本地。kafka存数据是存在topic 里面，kafka存消息是存到磁盘上的，默认保留七天，配置文件里写的是168个小时

#### 3.2、topic

​		看成是一个消息队列，因为生产者消费者面向的都是一个topic。

- partition分区

  为了实现扩展性，一个非常大的topic主题，会分布到多个broker（服务器）上。一个topic可以分为多个分区partition，而每个partition是一个有序队列。

- replication是副本

  为保证集群中，当某个节点发生故障时，保证节点上的数据不丢失，而且kafka还能继续工作，kafka提供了副本机制，也就是一个topic的每一个分区，都有许多个副本。也就是一个leader和许多个follower。当然follower肯定不能再同一个broker，不然副本毫无意义。

- leader副本

  leader是每个分区多个副本的主，生产者发送数据的对象，以及消费者消费数据的对象都是leader。每个分区多个副本的从，实时的从leader主副本同步数据，保持和leader数据同步，当某个leader分区挂了，某一个follwer从副本会成为新的leader分区启动kafka之前要先启动zk，因为kafka依赖于zk

- 消费者组consumer group

也就是同一个消费者组里面的消费者，消费topic不同分区，也就是不能消费同一个分区的数据

#### 3.3、关于leader何时向follwer发送ack

​		有两种想法，一是，半数以上的follwer同步完成数据，leader发送ack，但是这种解决方案，至少需要2n+1台服务器。容易造成资源浪费，还有很多重复的副本。第二种解决方案是，所有的服务器都同步完成，也就是总共有n+1台服务器，但是这样仍然有一个问题，就是，假如同步过程中，有一个follwer可能由于网络问题，长时间的没有和leader同步数据，这样就要一直等下去，容易造成资源浪费，因此就出现了ISR机制。kafka使用的是第二种方案
​		leader维护一个ISR（in sync replication set）叫做和follwer保持同步的集合，当ISR中的follwer和leader同步数据完成后，leader就会发出ack给follower。如果follwer长时间没有向leader同步数据，则这个follwer就会被踢出ISR，replica.lag.time.max.ms这个参数决定follwer的这个长时间的最大限度（默认值是10000ms，也就是10s之内同步完，否则被踢出isr）。如果leader挂了，就会选择follwer作为新的leader。选举follwer作为新的leader的时候，是看消息条数最多的，作为新的。因为数据越多的丢数据越少。

- ack的应答机制
    对某些不重要的数据，可靠性要求不是很高的数据，能够容忍少量丢失数据。所以，没必要等ISR中的的follwer都同步完数据。Kafka提供了3种可靠性级别，可以让用户使用的时候，对可靠性和延迟进行权衡。